<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Kate Hofmann - ML Portfolio</title>

  <!-- Bootstrap core CSS -->
  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Custom styles for this template -->
  <link href="css/scrolling-nav.css" rel="stylesheet">

</head>

<body id="page-top">

  <!-- Navigation -->
  <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
    <div class="container">
      <a class="navbar-brand js-scroll-trigger" href="#page-top">Kate Hofmann</a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="navbarResponsive">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#about">About me</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#rl_project">RL Project</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#autoencoder">Autoencoder Project</a>
          </li>
          <li class="nav-item">
            <a class="nav-link js-scroll-trigger" href="#contact">Contact</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <header class="bg-primary text-white">
    <div class="container text-center">
      <h1>A Machine Learning Enthusiast</h1>
      <p class="lead">I’m passionate about machine learning. I love to code especially when going deep into the core. Algorithms, models, loss functions…</p>
    </div>
  </header>

  <section id="about">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto">
          <h2>About K8</h2>
          <p class="lead">This is a great place to talk about your webpage. This template is purposefully unstyled so you can use it as a boilerplate or starting point for you own landing page designs! This template features:</p>
          <ul>
            <li>Clickable nav links that smooth scroll to page sections</li>
            <li>Responsive behavior when clicking nav links perfect for a one page website</li>
            <li>Bootstrap's scrollspy feature which highlights which section of the page you're on in the navbar</li>
            <li>Minimal custom CSS so you are free to explore your own unique design options</li>
          </ul>
        </div>
      </div>
    </div>
  </section>

  <section id="rl_project" class="bg-light">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto">
          <h2>Reinforcement Learning Project</h2>
          <p class="lead">Behavioural science draws conclusions through the results of behavioural observations. In particular, it is trying to predict animal's internal states and processes based on indirect measurements and/or observations of the animal's behaviour. Cognitive science endeavors for years on revealing the content of the black box, as revealing the inner workings between input (stimuli) and output (response).</p>
          <p class="lead">The aim of our project was an implementation of a framework with models that imitate animal's behaviour and to evaluate, which model fits best animal's behaviour. This allows us to reveal the inner workings on the basis of very simple observations. The evaluation framework is composed of two components: models and evaluation. The framework's input are data, that describe a simple animal's behaviour in a form of trajectories in space and time. Models are fitted to the data, which in term generates new trajectories with fitted parameters. A newly generated trajectory is compared with an original one and an evaluation method returns an information about which model fits better to the inputs. The selected model reveals an underlying inner structure.</p>
          <h3>Implementation</h3>
          <p class="lead">The framework was implemented on a basis of a pilot study.
The design of the framework consists of two parts, divided into subparts:</p>
          <ul>
            <li>simulation framework
              <ul>
                <li>environment</li>
                <li>agent</li>
              </ul>
            </li>
            <li>agent's learning process
              <ul>
                <li>evaluation</li>
                <li>reconstruction</li>
              </ul>
            </li>
          </ul>
          <h4>Simulation framework</h4>
          <p class="lead">To implement simulation we use Markov Decision Process theory, which represents agent's internal states, beliefs and desires, its planning process and its interaction with the environment and encodes environment's limits.</p>
          <pre>
            <code> 
              <small>
def simulate (self, 
              n=1000,              x0=0, y0=0, x_vel0=0, y_vel0=0, angular_vel0=0, heading0=0,              **_):
        # The first state will be the original state
        states = [pd.Series(dict(x=x0, y=y0,
                                 x_vel=x_vel0, y_vel=y_vel0,
                                 angular_vel=angular_vel0,
                                 heading=heading0))]
        # Run n steps
        for _ in range(n):
            # noinspection PyArgumentList
            states.append(self.next(**states[-1]))

        # Return a dataframe with all the observations, indexed by time [sec]
        return pd.DataFrame(states, index=np.arange(n + 1) * self.dt)
              </small>
            </code>
          </pre>
          <p class="lead">To train an agent to imitate animals behaviour we used reinforcement learning. RL is a computational approach, that addresses the problem of how agents should learn to take actions to maximize cumulative reward through interactions with an environment.</p>
          <pre>
            <code>
              <small>
def fit(self, model_type):
        """
        Initializes TRPO (trust region policy optimization) algorithm and uses
        it to train the model, determined with model_type. After the training,
        the iteration that collected the best cumulative reward. A policy of 
        the iteration is saved to a blobal variable and the associated 
        trajectory saved to pickle file.
        
        Parameters
        ----------
        model_type : string
            name of a model, that is to be fit to the ground truth trajectories.
            Valid types are:
            - 'object_approaching_model'
            - 'object_avoidance_model'
            - 'reflexive_goal_oriented_model'
            
        Returns
        -------
        float
            cumulative reward, collected at the best iteration
        """
        episode_provider = Episodes(ground_truth_model=self.ground_truth_model,
                                    fitting_model=fitting_model,
                            initial_observations=self.train_initial_observations,
                                    snapshot_dir=self.directory,
                                    train=True)

        env = TrajectoryImitationEnv(episode_provider=episode_provider,
                                     one_step_forecast=False)
        self.norm_env = normalize(env, normalize_reward=True)

        # creates an agent
        policy = GaussianMLPPolicy(env_spec=self.norm_env.spec,
                                   hidden_sizes=self.network_setup)

        baseline = LinearFeatureBaseline(env_spec=self.norm_env.spec)
        self.algo = TRPO(
            env=self.norm_env,
            policy=policy,
            baseline=baseline,
            n_itr=NUMBER_OF_ITERATIONS,
            store_paths=True,
            discount=self.discount_factor,
            n_samples=int(round(self.number_of_data * 0.66)),
            batch_size=int(round(self.number_of_data * 0.66)) 
                           * self.max_path_length,
            max_path_length=self.max_path_length
        )
        self.algo.train()

        iteration_data_dict = joblib.load(op.join(self.model_directory,
                                                  ('itr_%s.pkl' 
                                                  % (NUMBER_OF_ITERATIONS - 1))))

        cumulative_reward = self.get_cumulative_reward(iteration_data_dict)
        self.policy = iteration_data_dict['policy']
        [self.log_reconstructed_trajectory(path, index) for index, path in
         enumerate(iteration_data_dict['paths'])]
        return cumulative_reward
              </small>
            </code>
          </pre> 
          <h4>Models</h4>
          <p class="lead">Each model stands for every hypothesis. It models animal’s behaviour and as such should be distinguished from an ML model. A model describes a trajectory in terms of differential equations using x, y positions, x, y velocities, angle, angular velocity and position of an object on agent's retina at each time point.</p>
          <p class="lead">Three different models were implemented. A model that describes an animal approaching a goal, an animal that is avoiding an obstacle and reflexive & goal oriented model as a combination of first two.</p>
          <pre>
            <code>
              <small>
def next(self, x, y, x_vel, y_vel, heading, angular_vel, **_):
        """
        Method generates a next observation, based on given values, a previous 
        observation. For a calculation is using semi differential equations.

        An angle between an agent heading and an object's direction dictates 
        the torque, which is multiplied by a scalar value, called gain.

        Parameters
        ----------
        x : float
            x position of previous observation            [m]
        y : float
            y position of previous observation            [m]
        x_vel : float
            velocity along x axis of previous observation [m/s]
        y_vel : float
            velocity along y axis of previous observation [m/s]
        heading : float
            angle in which an agent is moving of prev observation, 
            in range [o, 2 * pi]                          [rad]
        angular_vel : float
            angular velocity of previous observation      [rad/s]

        Returns
        -------
        pd.Series
            the calculated next observation
        """
        # --- Avoid selfishness
        dt = self.dt  # s
        mass = self.mass  # kg
        object_x, object_y = self.object_location  # m
        gain = self.gain  # N * m / rad
        rot_inertia = self.rot_inertia  # kg * m^2
        rot_damping = self.rot_damping  # unitless
        force_forward = self.force_forward  # N
        air_drag = self.air_drag  # unitless
        # force_lateral = self.force_lateral  # N

        # Rotational force due to attraction/repulsion towards object
        agent_object_angle = math.atan2(object_y - y, object_x - x)
        position_retina = wrap_pi_pi(agent_object_angle - heading)  
        torque = gain * position_retina  # N * m

        angular_velocity_new = angular_vel + dt / rot_inertia 
                               * (- rot_damping * angular_vel + torque)

        heading_new = heading + angular_vel * dt

        # Velocities
        x_vel_new = x_vel + dt / mass * (- air_drag * x_vel + force_forward 
                                         * math.cos(heading))
        y_vel_new = y_vel + dt / mass * (- air_drag * y_vel + force_forward
                                         * math.sin(heading))

        # Positions
        x_new = x + x_vel * dt
        y_new = y + y_vel * dt

        # Result dictionary (or named tuple or...)
        new_state = {
            'x': x_new, 'y': y_new,
            'x_vel': x_vel_new, 'y_vel': y_vel_new,
            'heading': heading_new,
            'angular_vel': angular_velocity_new,
        }

        return pd.Series(new_state)
              </small>
            </code>
          </pre>
          <h5>Evaluation</h5>
          <p class="lead">Training is guided through cumulative reward, which is a good metric to evaluate models.</p>
        </div>
      </div>
    </div>
  </section>

  <section id="autoencoder">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto">
          <h2>LSTM Autoencoder Project</h2>
          <p class="lead">Carsharing companies encounter plenty of unreported damages on cars, which ends up being quite costly. The idea of the project was to implement a system that would detect damages in real time using simple vibration sensors. To determine whether a signal means that actual damage occured or a driver was simply driving on a gravel we used a machine learning algorithm.</p>
          <h3>Implementation</h3>
          <p class="lead">Each system gets calibrated for every type of a car. During calibration phase we collected signals and converted them into audio files. The data got preprocess and fit to a model. In production phase the data get stored in a cloud where a pretrained model is used for classification.</p>
          <h4>LSTM Autoencoder</h4>
          <p class="lead">Autoencoder consist of two parts: an encoder and a decoder. Once fit the encoder compresses the data, whereas the decoder reconstructs an original signal. The general idea of autoencoder is that the model is trained only on non-anomalous data, therefore a compression and a reconstruction of an original signal of anomalous data will result in bigger reconstruction error.</p>
          <p class="lead">An example of a model implementation:</p>
          <pre>
            <code>
              <small>
@property
def model(self):
    inp_e = Input((20, 800))  # here, you don't define the batch size
    out_e = LSTM(units=80, return_sequences=False)(inp_e)

    encoder = Model(inp_e, out_e)

    inp_d = Input((80,))
    out_d = Reshape((20, 4))(inp_d)  # supposing 20 steps of 4 elements
    out_d1 = LSTM(800, return_sequences=True)(out_d)  

    decoder = Model(inp_d, out_d1)

    model = Model(encoder.inputs, decoder(encoder(encoder.inputs)))

    return model
              </small>
            </code>
          </pre> 
          <h3>Results</h3>
          <p class="lead">Next figure demonstrates a reconstruction error for anomalous and non-anomalous data.</p>
          <p class="aligncenter">
            <figure>
              <img src="reconstruction_error.png" width="304" height="228">
              <span>A figure demonstrates that a model was trained sufficiently well and that a threshold value could be set properly to separate classes based on reconstruction error.</span>
            </figure>
          </p>
          <p class="lead">As expected such model gives positive results:</p>
          <p class="aligncenter">
            <figure>
              <img src="roc_curve.png" width="304" height="228">
              <span>A figure plots ROC curve with AUC of 96,15 %.</span>
            </figure>
          </p>
        </div>
      </div>
    </div>
  </section>

  <section id="contact">
    <div class="container">
      <div class="row">
        <div class="col-lg-8 mx-auto">
          <h2>Contact</h2>
          <p class="lead">Kate Hofmann</p>
          <p class="lead"><a href="mailto:k8hofmann@gmail.com">e-mail</a></p>
          <p class="lead">+49176 8801 7477</p>
          <p class="lead"><a href="https://de.linkedin.com/in/kate-hofmann-14b08b130" target="_blank">LinkedIn</a></p>
        </div>
      </div>
    </div>
  </section>

  <!-- Footer -->
  <footer class="py-5 bg-dark">
    <div class="container">
      <p class="m-0 text-center text-white">Copyright &copy; k8h.github.io 2019</p>
    </div>
    <!-- /.container -->
  </footer>

  <!-- Bootstrap core JavaScript -->
  <script src="vendor/jquery/jquery.min.js"></script>
  <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  <!-- Plugin JavaScript -->
  <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

  <!-- Custom JavaScript for this theme -->
  <script src="js/scrolling-nav.js"></script>

</body>

</html>
